import math

def entropy(data):
    labels = [item[-1] for item in data]
    return -sum((labels.count(label)/len(data)) * math.log2(labels.count(label)/len(data)) for label in set(labels))

def split_data(data, feature, value):
    return [item for item in data if item[feature] == value]

def build_tree(data):
    if len(set([item[-1] for item in data])) == 1:
        return data[0][-1]
    
    best_feature, best_value = min(
        [(f, v) for f in range(len(data[0])-1) for v in set([item[f] for item in data])],
        key=lambda x: entropy(split_data(data, x[0], x[1]))
    )
    
    tree = {best_feature: {}}
    for value in set([item[best_feature] for item in data]):
        tree[best_feature][value] = build_tree(split_data(data, best_feature, value))
    
    return tree

def classify(tree, instance):
    if isinstance(tree, dict):
        return classify(tree[list(tree.keys())[0]][instance[list(tree.keys())[0]]], instance)
    return tree

# Sample data
data = [
    [0, 0, 'No'],
    [0, 1, 'No'],
    [1, 0, 'Yes'],
    [1, 1, 'Yes'],
    [2, 0, 'No'],
    [2, 1, 'Yes']
]

tree = build_tree(data)
print("Tree:", tree)
test_instance = [1, 1]  # Example: Age 31-40, Income Medium
print("Prediction:", classify(tree, test_instance))
